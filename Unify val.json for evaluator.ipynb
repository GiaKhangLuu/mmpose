{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd156be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "Due to the error while evaluating multiple validation sets. We have to \n",
    "unify all val.json files into a single file.\n",
    "\"\"\"\n",
    "\n",
    "# Root directory where your data folders are stored\n",
    "root_dir = 'data'\n",
    "side = \"left\"\n",
    "phase = \"val\"\n",
    "\n",
    "# Find all val.json files in the given folder structure\n",
    "val_files = glob(os.path.join(root_dir, '*/*/image/{}/annotations/{}.json'.format(side, phase)))\n",
    "\n",
    "# Initialize the combined data structure\n",
    "combined_data = {\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': [],\n",
    "}\n",
    "\n",
    "# Counters to avoid duplicate ids\n",
    "image_id_offset = 0\n",
    "annotation_id_offset = 0\n",
    "\n",
    "# Loop over all val.json files and merge them\n",
    "side = \"left\"\n",
    "for file in val_files:\n",
    "    folders = file.split(\"/\")\n",
    "    date, date_time = folders[1], folders[2]\n",
    "    img_rel_path = os.path.join(date, date_time, \"image\", side, phase)\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Adjust image_ids and annotation_ids to avoid conflicts\n",
    "    for image in data['images']:\n",
    "        # Update file_name to be a relative path from the data folder\n",
    "        image_path = os.path.relpath(os.path.join(os.path.dirname(file), '..', '..', image['file_name']), root_dir)\n",
    "        image['file_name'] = os.path.join(img_rel_path, image[\"file_name\"])\n",
    "        \n",
    "        # Update image ID\n",
    "        image['id'] += image_id_offset\n",
    "    \n",
    "    for annotation in data['annotations']:\n",
    "        annotation['id'] += annotation_id_offset\n",
    "        annotation['image_id'] += image_id_offset\n",
    "\n",
    "    # Update the combined data\n",
    "    combined_data['images'].extend(data['images'])\n",
    "    combined_data['annotations'].extend(data['annotations'])\n",
    "    \n",
    "    # Assuming categories are the same across all files\n",
    "    if not combined_data['categories']:\n",
    "        combined_data['categories'] = data['categories']\n",
    "    \n",
    "    # Update the offsets\n",
    "    image_id_offset = max(image['id'] for image in combined_data['images']) + 1\n",
    "    annotation_id_offset = max(annotation['id'] for annotation in combined_data['annotations']) + 1\n",
    "\n",
    "# Save the combined val.json\n",
    "output_file = os.path.join(root_dir, 'unified_val.json')\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(combined_data, f)\n",
    "\n",
    "print(f\"Unified val.json saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
